{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"自作プロダクト課題.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMbyCoPGDjWIMwfEDddJY8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6i8E_pRySTpg"},"source":["# LSTMを用いたテキスト分類\n","【概要】\n","\n","データセットはlivedoor ニュースコーパスを使用．\n","各ニュース記事は９種類のカテゴリに分類されている．\n","ニュース記事のタイトルを入力とし，推測したカテゴリを出力する．\n","\n","GPUを利用するため，Google colaboratory上で実行．\n","\n","実行する前に，編集→ノートブックの設定でGPUを選択する．\n","\n","データの流れは以下の通り．\n","\n","ニュース記事からタイトル文字列を抽出\n","\n","↓\n","\n","形態素解析を行い，文字列を形態素に分割し，各形態素をIDに変換\n","\n","↓\n","\n","エンべディング層に入力\n","\n","↓\n","\n","LSTM層に入力\n","\n","↓\n","\n","Affine層に入力\n","\n","↓\n","\n","Softmax層に入力\n","\n","↓\n","\n","カテゴリの確率を出力\n","\n","\n","\n","---\n","\n","\n","【工夫点】\n","\n","１．過学習が疑われるため，ドロップアウトを適用\n","\n","２．タイトル+本文を入力データとして利用\n","\n","３．LSTM層の多層化，Bidirectional化によるモデルの改良\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"c3-_ECJSUziV","executionInfo":{"status":"ok","timestamp":1603107217430,"user_tz":-540,"elapsed":586,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"911b9916-6024-4ad8-eda3-cf87c492eccf","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Googleドライブ上のファイルにアクセスするためのマウント設定\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vYUdnK64VuYZ","executionInfo":{"status":"ok","timestamp":1603107219987,"user_tz":-540,"elapsed":3136,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"df12bdec-2950-458a-84e8-0f436c4c7f07","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["pip install mecab-python3==0.996.5"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mecab-python3==0.996.5 in /usr/local/lib/python3.6/dist-packages (0.996.5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1i81LW83WUyL"},"source":["データセットのフォルダにアクセスし，データフレームを作成する．\n","各列のラベルはそれぞれ，タイトル，タイトル+本文，カテゴリー．"]},{"cell_type":"code","metadata":{"id":"qm6f2TSzV-bH"},"source":["#import os\n","#from glob import glob\n","#import pandas as pd\n","#import linecache\n","\n","#drive_dir = \"drive/My Drive/自作課題/\"\n","\n","#categories = [name for name in os.listdir(drive_dir + 'text') if os.path.isdir(drive_dir + \"text/\" +name)]\n","#print(categories)\n","\n","#datasets = pd.DataFrame(columns=[\"title\", \"text\", \"category\"])\n","#for cat in categories:\n","#    path = drive_dir + \"text/\" + cat + \"/*.txt\"\n","#    files = glob(path)\n","#    for file in files:\n","#        with open(file, 'r') as f:\n","#            lines = f.read().splitlines()\n","#            title = lines[2]\n","#            body = \"\\n\".join(lines[3:])\n","#            text = title + \"\\n\" + body\n","#        s = pd.Series([title, text, cat], index=datasets.columns)\n","#        datasets = datasets.append(s, ignore_index=True)\n","#datasets.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tS77FihiYNVQ"},"source":["↑を毎回実行すると時間がかかるため，一度作成したデータフレームを保存して再利用する．"]},{"cell_type":"code","metadata":{"id":"YfZnqc4pXtrd","executionInfo":{"status":"ok","timestamp":1603107220342,"user_tz":-540,"elapsed":3480,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"8fbf51d0-5ed9-462c-80dd-b808f5b619d8","colab":{"base_uri":"https://localhost:8080/","height":324}},"source":["import os\n","import pandas as pd\n","\n","drive_dir = \"drive/My Drive/自作課題/\"\n","\n","datasets = pd.read_csv(drive_dir + \"text.csv\")\n","categories = [name for name in os.listdir(drive_dir + 'text') if os.path.isdir(drive_dir + \"text/\" +name)]\n","print(categories)\n","datasets.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['dokujo-tsushin', 'smax', 'livedoor-homme', 'kaden-channel', 'it-life-hack', 'sports-watch', 'peachy', 'topic-news', 'movie-enter']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>title</th>\n","      <th>text</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>コンプレックスを自信に変える女たち</td>\n","      <td>コンプレックスを自信に変える女たち\\nどんな人でもコンプレックスを持っているのではないか。\\...</td>\n","      <td>dokujo-tsushin</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>親が倒れた時、独女は何ができるのか？</td>\n","      <td>親が倒れた時、独女は何ができるのか？\\n「親ももう60歳すぎているし、いつ何があってもおかし...</td>\n","      <td>dokujo-tsushin</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>ただの女友達と好きな女の境界線</td>\n","      <td>ただの女友達と好きな女の境界線\\n職場で気が合い、話も弾み、ときにはふたりで食事に行くことも...</td>\n","      <td>dokujo-tsushin</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>【オトナ女子映画部】少女マンガ的な妄想ふくらむ“鉄板”ラブコメ『Black &amp; White/...</td>\n","      <td>【オトナ女子映画部】少女マンガ的な妄想ふくらむ“鉄板”ラブコメ『Black &amp; White/...</td>\n","      <td>dokujo-tsushin</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>男性の言い分「独女の食事スタイル、ここが納得いかない！」</td>\n","      <td>男性の言い分「独女の食事スタイル、ここが納得いかない！」\\n男性と女性は同じ人間でも特性は全...</td>\n","      <td>dokujo-tsushin</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  ...        category\n","0           0  ...  dokujo-tsushin\n","1           1  ...  dokujo-tsushin\n","2           2  ...  dokujo-tsushin\n","3           3  ...  dokujo-tsushin\n","4           4  ...  dokujo-tsushin\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"L7JEafO-ZSPT"},"source":["文字列を形態素に分解する関数を定義"]},{"cell_type":"code","metadata":{"id":"f0rP-q0wY5os"},"source":["import MeCab\n","import re\n","\n","tagger = MeCab.Tagger(\"-Owakati\")\n","\n","def make_wakati(sentence):\n","    sentence = tagger.parse(sentence)\n","    sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n","    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n","    wakati = sentence.split(\" \")\n","    wakati = list(filter((\"\").__ne__, wakati))\n","    return wakati"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nIi2c1gHZ14Y"},"source":["タイトル文字列を形態素に分解し，各形態素にIDを振り分け，形態素とIDの対応リストを作成．"]},{"cell_type":"code","metadata":{"id":"ZOC96tGnZ2Wh","executionInfo":{"status":"ok","timestamp":1603107220744,"user_tz":-540,"elapsed":3871,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"b78a454d-06fe-4032-851a-e8efb615d3fc","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["word2index = {}\n","# 系列を揃えるためのパディング文字列<pad>を追加\n","# パディング文字列のIDは0とする\n","word2index.update({\"<pad>\":0})\n","\n","for title in datasets[\"title\"]:\n","    wakati = make_wakati(title)\n","    for word in wakati:\n","        if word in word2index:  continue\n","        word2index[word] = len(word2index)\n","\n","print(\"vocab size : \", len(word2index))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["vocab size :  13230\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HNAHmEfMcBCD"},"source":["学習データのミニバッチを作成するために，各文字列データの系列長を揃える必要がある．\n","\n","短い系列長のデータにパディングを追加し，最長のデータの系列長に揃える．"]},{"cell_type":"code","metadata":{"id":"WRCJ-oeEcBWf"},"source":["from sklearn.model_selection import train_test_split\n","import random\n","from sklearn.utils import shuffle\n","\n","# カテゴリーとIDの対応リストを作成\n","cat2index = {}\n","for cat in categories:\n","    if cat in cat2index: continue\n","    cat2index[cat] = len(cat2index)\n","\n","# 入力した文字列を形態素に分解し，各形態素をIDに変換する関数\n","def sentence2index(sentence):\n","    wakati = make_wakati(sentence)\n","    return [word2index[w] for w in wakati]\n","\n","# 入力したカテゴリーをIDに変換する関数\n","def category2index(cat):\n","    return [cat2index[cat]]\n","\n","index_datasets_title_tmp = []\n","index_datasets_category = []\n","\n","# バッチ化のために各文字列データの系列長を揃える\n","# 系列の長さの最大値を取得。この長さに他の系列の長さをあわせる\n","max_len = 0\n","for title, category in zip(datasets[\"title\"], datasets[\"category\"]):\n","    index_title = sentence2index(title)\n","    index_category = category2index(category)\n","    index_datasets_title_tmp.append(index_title)\n","    index_datasets_category.append(index_category)\n","    if max_len < len(index_title):\n","        max_len = len(index_title)\n","\n","# 系列の長さを揃えるために短い系列にパディングを追加\n","index_datasets_title = []\n","for title in index_datasets_title_tmp:\n","    for i in range(max_len - len(title)):\n","        title.insert(0, 0) # 前パディング\n","#      title.append(0)　# 後ろパディング\n","    index_datasets_title.append(title)\n","\n","train_x, test_x, train_y, test_y = train_test_split(index_datasets_title, index_datasets_category, train_size=0.8, random_state=11)\n","\n","# データをバッチでまとめるための関数\n","def train2batch(title, category, batch_size=32):\n","    title_batch = []\n","    category_batch = []\n","    title_shuffle, category_shuffle = shuffle(title, category)\n","    for i in range(0, len(title), batch_size):\n","        title_batch.append(title_shuffle[i:i+batch_size])\n","        category_batch.append(category_shuffle[i:i+batch_size])\n","    return title_batch, category_batch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n-Okbb7we817"},"source":["ベースモデル定義"]},{"cell_type":"code","metadata":{"id":"3mCDr7t7ebnZ"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# GPUを使うために必要\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# ベースモデル\n","class LSTMClassifier(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n","        super(LSTMClassifier, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        # <pad>の単語IDが0なので、padding_idx=0としている\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        # batch_first=Trueとすることで入力テンソルの型を(batch_size × len(sentence) × embedding_dim)にできる\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n","        self.softmax = nn.LogSoftmax()\n","    \n","    def forward(self, sentence):\n","        embeds = self.word_embeddings(sentence)\n","        #embeds.size() = (batch_size × len(sentence) × embedding_dim)\n","        _, lstm_out = self.lstm(embeds)\n","        # lstm_out[0].size() = (1 × batch_size × hidden_dim)\n","        tag_space = self.hidden2tag(lstm_out[0])\n","        # tag_space.size() = (1 × batch_size × tagset_size)\n","\n","         # (batch_size × tagset_size)にするために次元削減squeeze()する\n","        tag_scores = self.softmax(tag_space.squeeze())\n","         # tag_scores.size() = (batch_size × tagset_size)\n","\n","        return tag_scores\n","\n","EMBEDDING_DIM = 200\n","HIDDEN_DIM = 128\n","VOCAB_SIZE = len(word2index)\n","TAG_SIZE = len(categories)\n","# to(device)でモデルがGPU対応する\n","model_base = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE).to(device)\n","loss_function_base = nn.NLLLoss()\n","optimizer_base = optim.Adam(model_base.parameters(), lr=0.001)\n","#勾配クリッピングの閾値\n","max_norm = 5.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Epb682f4g2UM"},"source":["\n","学習"]},{"cell_type":"code","metadata":{"id":"jRQRJaS8f_NP","executionInfo":{"status":"ok","timestamp":1603107262054,"user_tz":-540,"elapsed":45168,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"190dc92e-619b-4ccb-d60c-a4de4194d8b1","colab":{"base_uri":"https://localhost:8080/","height":973}},"source":["def trainer(train_x, train_y, model, loss_function, optimizer):\n","    losses = []\n","    model.train()\n","    for epoch in range(50):\n","        all_loss = 0\n","        title_batch, category_batch = train2batch(train_x, train_y)\n","        for i in range(len(title_batch)):\n","            batch_loss = 0\n","\n","            model.zero_grad()\n","            \n","            # 順伝搬させるtensorはGPUで処理させるためdevice=にGPUをセット\n","            title_tensor = torch.tensor(title_batch[i], device=device)\n","            # category_tensor.size() = (batch_size × 1)なので、squeeze()\n","            category_tensor = torch.tensor(category_batch[i], device=device).squeeze()\n","\n","            out = model(title_tensor)\n","\n","            batch_loss = loss_function(out, category_tensor)\n","            batch_loss.backward()\n","            # 勾配クリッピング\n","            #nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n","            optimizer.step()\n","\n","            all_loss += batch_loss.item()\n","        print(\"epoch\", epoch, \"\\t\", \"loss\", all_loss)\n","        if all_loss < 0.1: break\n","    print(\"done.\")\n","\n","trainer(train_x, train_y, model_base, loss_function_base, optimizer_base)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 0 \t loss 278.3312571644783\n","epoch 1 \t loss 156.70109927654266\n","epoch 2 \t loss 89.34506480395794\n","epoch 3 \t loss 44.169016391038895\n","epoch 4 \t loss 21.022379517555237\n","epoch 5 \t loss 9.119648973457515\n","epoch 6 \t loss 5.243457025848329\n","epoch 7 \t loss 2.3246719921007752\n","epoch 8 \t loss 1.4754446597071365\n","epoch 9 \t loss 1.203811745508574\n","epoch 10 \t loss 1.0188539265072905\n","epoch 11 \t loss 0.9150644512847066\n","epoch 12 \t loss 0.8696114233171102\n","epoch 13 \t loss 0.7987178986077197\n","epoch 14 \t loss 0.7742376437236089\n","epoch 15 \t loss 0.7221189943957143\n","epoch 16 \t loss 0.691118494287366\n","epoch 17 \t loss 0.6712544714828255\n","epoch 18 \t loss 0.6512145747401519\n","epoch 19 \t loss 0.6481697559793247\n","epoch 20 \t loss 0.6375674666051054\n","epoch 21 \t loss 0.5930877310602227\n","epoch 22 \t loss 0.5968639991406235\n","epoch 23 \t loss 0.5845328932846314\n","epoch 24 \t loss 0.5722149166176678\n","epoch 25 \t loss 0.5805848214949947\n","epoch 26 \t loss 0.570289440878696\n","epoch 27 \t loss 0.5622812460824207\n","epoch 28 \t loss 0.5512585903634317\n","epoch 29 \t loss 0.5613317901479604\n","epoch 30 \t loss 0.5558817617638852\n","epoch 31 \t loss 0.5437645167949086\n","epoch 32 \t loss 0.5480419235700538\n","epoch 33 \t loss 0.5467534715571674\n","epoch 34 \t loss 0.5368098789185751\n","epoch 35 \t loss 0.533030602902727\n","epoch 36 \t loss 0.6586924263028777\n","epoch 37 \t loss 0.5289801959570468\n","epoch 38 \t loss 0.5264499844815873\n","epoch 39 \t loss 0.5257620776428666\n","epoch 40 \t loss 0.525550392236255\n","epoch 41 \t loss 0.524173316362976\n","epoch 42 \t loss 0.5225077317772957\n","epoch 43 \t loss 0.5226138598236503\n","epoch 44 \t loss 0.5212291962934614\n","epoch 45 \t loss 0.52120129454579\n","epoch 46 \t loss 0.5213047841716616\n","epoch 47 \t loss 0.5218497327005025\n","epoch 48 \t loss 0.5134702768691568\n","epoch 49 \t loss 0.519185134633517\n","done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tEJ4Hjqqhlcr"},"source":["テストデータによる推論・精度算出"]},{"cell_type":"code","metadata":{"id":"J03X-SIfhylR","executionInfo":{"status":"ok","timestamp":1603107262055,"user_tz":-540,"elapsed":45164,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"df3dc8aa-9a3b-4f73-9f0b-1b47b04f2273","colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["def accuracy(test_x, test_y, model):\n","    test_num = len(test_x)\n","    a = 0\n","    model.eval()\n","    with torch.no_grad():\n","        title_batch, category_batch = train2batch(test_x, test_y)\n","\n","        for i in range(len(title_batch)):\n","            title_tensor = torch.tensor(title_batch[i], device=device)\n","            category_tensor = torch.tensor(category_batch[i], device=device)\n","\n","            out = model(title_tensor)\n","            _, predicts = torch.max(out, 1)\n","            for j, ans in enumerate(category_tensor):\n","                if predicts[j].item() == ans.item():\n","                    a += 1\n","        return a / test_num\n","model_base_acc = accuracy(test_x, test_y, model_base)\n","print(\"model_base accuracy :\", model_base_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["model_base accuracy : 0.6795392953929539\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Eaw81i-ZjuVO"},"source":["精度があまり良くないので，学習データに対する精度をチェックする"]},{"cell_type":"code","metadata":{"id":"UUnRNv3JjCNm","executionInfo":{"status":"ok","timestamp":1603107262541,"user_tz":-540,"elapsed":45644,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"910e4567-0517-4f41-ea26-7c86958a4906","colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["model_base_acc_train = accuracy(train_x, train_y, model_base)\n","print(\"model_base train accuracy :\", model_base_acc_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["model_base train accuracy : 0.9988135593220339\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A5M-mmlekUcA"},"source":["学習データに対する精度が99%以上であるため，過学習を起こしていると考えられる．\n","\n","# 【ドロップアウトの適用】\n","\n","そこで，過学習を抑制し汎化性能を向上させるため，ドロップアウトを適用したモデルを作成する．\n","\n","ドロップアウトモデル定義"]},{"cell_type":"code","metadata":{"id":"GIv_MqVpkHke"},"source":["# ドロップアウトモデル\n","class DropLSTMClassifier(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n","        super(DropLSTMClassifier, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        # ドロップアウト層の定義\n","        self.dropout1 = nn.Dropout(0.5)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n","        self.softmax = nn.LogSoftmax()\n","    \n","    def forward(self, sentence):\n","        embeds = self.word_embeddings(sentence)\n","        # ドロップアウト層１\n","        embeds = self.dropout1(embeds)\n","        _, lstm_out = self.lstm(embeds)\n","        # ドロップアウト層２\n","        drop_out = self.dropout2(lstm_out[0])\n","        tag_space = self.hidden2tag(drop_out)\n","        tag_scores = self.softmax(tag_space.squeeze())\n","\n","        return tag_scores\n","\n","model_drop = DropLSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE).to(device)\n","loss_function_drop = nn.NLLLoss()\n","optimizer_drop = optim.Adam(model_drop.parameters(), lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PnQyIJtipTie"},"source":["ドロップアウトモデル学習"]},{"cell_type":"code","metadata":{"id":"3xpG3mxNm3OJ","executionInfo":{"status":"ok","timestamp":1603107304482,"user_tz":-540,"elapsed":87576,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"435af870-3c25-44fb-c36e-ad951e496094","colab":{"base_uri":"https://localhost:8080/","height":973}},"source":["trainer(train_x, train_y, model_drop, loss_function_drop, optimizer_drop)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 0 \t loss 347.0742018222809\n","epoch 1 \t loss 263.77784419059753\n","epoch 2 \t loss 224.72939485311508\n","epoch 3 \t loss 198.8028565645218\n","epoch 4 \t loss 176.46608859300613\n","epoch 5 \t loss 154.0020693540573\n","epoch 6 \t loss 140.04406183958054\n","epoch 7 \t loss 125.7641934454441\n","epoch 8 \t loss 112.59957931935787\n","epoch 9 \t loss 105.65650929510593\n","epoch 10 \t loss 93.74145624041557\n","epoch 11 \t loss 89.28340162336826\n","epoch 12 \t loss 79.0368916541338\n","epoch 13 \t loss 73.46407886594534\n","epoch 14 \t loss 68.80392841249704\n","epoch 15 \t loss 65.3428254276514\n","epoch 16 \t loss 58.01862517744303\n","epoch 17 \t loss 55.64290173724294\n","epoch 18 \t loss 52.02083423361182\n","epoch 19 \t loss 48.236286997795105\n","epoch 20 \t loss 45.80949308723211\n","epoch 21 \t loss 43.89563933387399\n","epoch 22 \t loss 39.43948703631759\n","epoch 23 \t loss 38.183571204543114\n","epoch 24 \t loss 34.30421833693981\n","epoch 25 \t loss 33.58682820573449\n","epoch 26 \t loss 30.886242234148085\n","epoch 27 \t loss 30.246362840756774\n","epoch 28 \t loss 29.766367103904486\n","epoch 29 \t loss 26.768711055628955\n","epoch 30 \t loss 34.707102285698056\n","epoch 31 \t loss 25.57652230653912\n","epoch 32 \t loss 25.289970678277314\n","epoch 33 \t loss 25.135554959066212\n","epoch 34 \t loss 21.78247779980302\n","epoch 35 \t loss 22.974856399931014\n","epoch 36 \t loss 22.400377923622727\n","epoch 37 \t loss 22.152647114824504\n","epoch 38 \t loss 20.859010515734553\n","epoch 39 \t loss 19.9671472995542\n","epoch 40 \t loss 17.99405713286251\n","epoch 41 \t loss 17.223355926107615\n","epoch 42 \t loss 15.401693433523178\n","epoch 43 \t loss 14.175667205825448\n","epoch 44 \t loss 15.430921376449987\n","epoch 45 \t loss 15.746612744173035\n","epoch 46 \t loss 15.142948656342924\n","epoch 47 \t loss 14.043808709364384\n","epoch 48 \t loss 12.731555573409423\n","epoch 49 \t loss 13.877937521319836\n","done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5P9CzzxcruX0"},"source":["ドロップアウトモデル推論・精度算出"]},{"cell_type":"code","metadata":{"id":"D7NdCRsapSCB","executionInfo":{"status":"ok","timestamp":1603107304483,"user_tz":-540,"elapsed":87572,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"f6b882b8-77f7-4e78-fc95-eaa16eed359b","colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["model_drop_acc = accuracy(test_x, test_y, model_drop)\n","print(\"model_base accuracy :\", model_base_acc)\n","print(\"model_drop accuracy :\", model_drop_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["model_base accuracy : 0.6795392953929539\n","model_drop accuracy : 0.7730352303523035\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"4x5TAlrGsAwg"},"source":["精度がやや向上した．\n","\n","ドロップアウトの適用により過学習を抑制する正則化が効いていると考えられる．"]},{"cell_type":"markdown","metadata":{"id":"Dir5miLzsc_A"},"source":["# 【タイトル＋本文を入力データにしてみる】\n","\n","続いて，タイトル+本文を入力データとした場合に精度が向上するか調査する．\n","\n","タイトル+本文のデータセットを構築"]},{"cell_type":"code","metadata":{"id":"VPXCyh04r6ma","executionInfo":{"status":"ok","timestamp":1603107310976,"user_tz":-540,"elapsed":94059,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"d463e6c7-905d-43df-b521-d0696ee859c3","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["word2index = {}\n","word2index.update({\"<pad>\":0})\n","\n","for title in datasets[\"text\"]:\n","    wakati = make_wakati(title)\n","    for word in wakati:\n","        if word in word2index:  continue\n","        word2index[word] = len(word2index)\n","\n","print(\"vocab size : \", len(word2index))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["vocab size :  59930\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TrH0oZ2BtjC2"},"source":["index_datasets_text_tmp = []\n","index_datasets_category = []\n","\n","# 系列の長さの最大値を取得。この長さに他の系列の長さをあわせる\n","max_len = 0\n","for text, category in zip(datasets[\"text\"], datasets[\"category\"]):\n","    index_text = sentence2index(text)\n","    index_category = category2index(category)\n","    index_datasets_text_tmp.append(index_text)\n","    index_datasets_category.append(index_category)\n","    if max_len < len(index_text):\n","        max_len = len(index_text)\n","\n","# 系列の長さを揃えるために短い系列にパディングを追加\n","index_datasets_text = []\n","for text in index_datasets_text_tmp:\n","    for i in range(max_len - len(text)):\n","        text.insert(0, 0) # 前パディング\n","#      title.append(0)　# 後ろパディング\n","    index_datasets_text.append(text)\n","\n","train_x_full, test_x_full, train_y_full, test_y_full = train_test_split(index_datasets_text, index_datasets_category, train_size=0.8, random_state=11)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y7EPyo7RvDRa"},"source":["モデル定義\n","\n","先ほどのドロップアウトモデルを利用"]},{"cell_type":"code","metadata":{"id":"g33tVxAhtwc5","executionInfo":{"status":"ok","timestamp":1603107355316,"user_tz":-540,"elapsed":138390,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"8fa1dee9-e910-4d8f-a3dc-6376901389a8","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["EMBEDDING_DIM = 200\n","HIDDEN_DIM = 128\n","VOCAB_SIZE = len(word2index)\n","TAG_SIZE = len(categories)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model_full = DropLSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE).to(device)\n","loss_function_full = nn.NLLLoss()\n","optimizer_full = optim.Adam(model_full.parameters(), lr=0.001)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NK5Ev7IdvVy2"},"source":["タイトル+本文データ学習"]},{"cell_type":"code","metadata":{"id":"5kZZn-8nvnd-","executionInfo":{"status":"ok","timestamp":1603109238283,"user_tz":-540,"elapsed":2021351,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"8fc2313a-13c4-46d7-825e-c76c17365c83","colab":{"base_uri":"https://localhost:8080/","height":973}},"source":["trainer(train_x_full, train_y_full, model_full, loss_function_full, optimizer_full)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 0 \t loss 308.6572422981262\n","epoch 1 \t loss 204.9768026471138\n","epoch 2 \t loss 153.79789212346077\n","epoch 3 \t loss 139.21663016080856\n","epoch 4 \t loss 124.4324600994587\n","epoch 5 \t loss 99.41649608314037\n","epoch 6 \t loss 89.65364748239517\n","epoch 7 \t loss 75.95142197608948\n","epoch 8 \t loss 63.41925152763724\n","epoch 9 \t loss 76.62054872885346\n","epoch 10 \t loss 63.36690326780081\n","epoch 11 \t loss 50.78928077034652\n","epoch 12 \t loss 42.91469419002533\n","epoch 13 \t loss 40.772968439385295\n","epoch 14 \t loss 39.07394891232252\n","epoch 15 \t loss 33.04709302447736\n","epoch 16 \t loss 31.403015030547976\n","epoch 17 \t loss 32.72948788944632\n","epoch 18 \t loss 27.228899087756872\n","epoch 19 \t loss 25.301443964242935\n","epoch 20 \t loss 22.68157380167395\n","epoch 21 \t loss 29.51691563008353\n","epoch 22 \t loss 22.72107018623501\n","epoch 23 \t loss 31.833334304392338\n","epoch 24 \t loss 26.924013352021575\n","epoch 25 \t loss 19.625721542863175\n","epoch 26 \t loss 18.177563628181815\n","epoch 27 \t loss 17.033250245265663\n","epoch 28 \t loss 16.306104346178472\n","epoch 29 \t loss 13.683180630905554\n","epoch 30 \t loss 12.899730553501286\n","epoch 31 \t loss 12.361113450489938\n","epoch 32 \t loss 12.127599966246635\n","epoch 33 \t loss 10.393211475777207\n","epoch 34 \t loss 10.696501139900647\n","epoch 35 \t loss 9.584749560774071\n","epoch 36 \t loss 9.566018142038956\n","epoch 37 \t loss 9.966730730549898\n","epoch 38 \t loss 9.043433687882498\n","epoch 39 \t loss 7.13350409688428\n","epoch 40 \t loss 7.24979521689238\n","epoch 41 \t loss 9.945294357661624\n","epoch 42 \t loss 7.562204473942984\n","epoch 43 \t loss 13.736369232996367\n","epoch 44 \t loss 18.27327188034542\n","epoch 45 \t loss 11.093111049907748\n","epoch 46 \t loss 6.869454892468639\n","epoch 47 \t loss 20.27613621216733\n","epoch 48 \t loss 12.829322200850584\n","epoch 49 \t loss 10.211387940158602\n","done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K-gkKfgN3ttm"},"source":["タイトル+本文モデル推論・精度算出"]},{"cell_type":"code","metadata":{"id":"ZUoMMB4KwRcK","executionInfo":{"status":"ok","timestamp":1603109242119,"user_tz":-540,"elapsed":2025181,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"d12ca15a-a07d-469d-e263-7300a54628f8","colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["model_full_acc = accuracy(test_x_full, test_y_full, model_full)\n","print(\"model_base accuracy :\", model_base_acc)\n","print(\"model_drop accuracy :\", model_drop_acc)\n","print(\"model_full accuracy :\", model_full_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["model_base accuracy : 0.6795392953929539\n","model_drop accuracy : 0.7730352303523035\n","model_full accuracy : 0.9092140921409214\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bQWpUJaQb-Ug"},"source":["タイトル+本文を入力データとすることで精度が大きく向上した。\n","\n","本文はタイトルよりも文字数が非常に多く、特徴的な単語が多く含まれていることが、精度の向上に寄与していると考えられる。\n","\n","また、LSTMによって系列の長い本文データであっても学習できることがわかる。"]},{"cell_type":"markdown","metadata":{"id":"K1btPrsbdHzR"},"source":["# 【モデルの改良】\n","\n","続いて，タイトル+本文を入力データとし、モデルをさらに改良した場合に精度が向上するか調査する。\n","モデルには以下の2つの改良を加える。\n","\n","①LSTM層の多層化（LSTM層を3層積層する）\n","\n","②LSTM層のBidirectional化\n","\n","\n","改良モデル定義"]},{"cell_type":"code","metadata":{"id":"1AgiwOgLQsqr"},"source":["# 改良モデル\n","class DeepLSTMClassifier(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n","        super(DeepLSTMClassifier, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.dropout1 = nn.Dropout(0.5)\n","        # ①LSTM層を3層積層、②Bidirectional化\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=3, batch_first=True, dropout=0.5, bidirectional=True)\n","        self.dropout2 = nn.Dropout(0.5)\n","        # Bidirectional化で隠れユニット次元数が倍増する\n","        self.hidden2tag = nn.Linear(hidden_dim * 2, target_size)\n","        self.softmax = nn.LogSoftmax()\n","    \n","    def forward(self, sentence):\n","        embeds = self.word_embeddings(sentence)\n","        embeds = self.dropout1(embeds)\n","        _, bilstm_hc = self.lstm(embeds)\n","        bilstm_out = torch.cat([bilstm_hc[0][-2], bilstm_hc[0][-1]], dim=1)\n","        drop_out = self.dropout2(bilstm_out)\n","        tag_space = self.hidden2tag(drop_out)\n","        tag_scores = self.softmax(tag_space.squeeze())\n","\n","        return tag_scores\n","\n","EMBEDDING_DIM = 200\n","HIDDEN_DIM = 128\n","VOCAB_SIZE = len(word2index)\n","TAG_SIZE = len(categories)\n","\n","model_deep = DeepLSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE).to(device)\n","loss_function_deep = nn.NLLLoss()\n","optimizer_deep = optim.Adam(model_deep.parameters(), lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XH1tNwZLgfJ-"},"source":["改良モデルの学習（入力データはタイトル+本文）"]},{"cell_type":"code","metadata":{"id":"8-Fuzz5fgipl","executionInfo":{"status":"ok","timestamp":1603122555536,"user_tz":-540,"elapsed":15338590,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"bd0a2ad1-bed5-4385-94b4-c60120197c8b","colab":{"base_uri":"https://localhost:8080/","height":973}},"source":["trainer(train_x_full, train_y_full, model_deep, loss_function_deep, optimizer_deep)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 0 \t loss 301.7329161763191\n","epoch 1 \t loss 193.9149765074253\n","epoch 2 \t loss 147.99074018001556\n","epoch 3 \t loss 137.1787267625332\n","epoch 4 \t loss 106.96926374733448\n","epoch 5 \t loss 102.14768919348717\n","epoch 6 \t loss 96.81617532670498\n","epoch 7 \t loss 81.20886664092541\n","epoch 8 \t loss 69.31662288308144\n","epoch 9 \t loss 67.86532012373209\n","epoch 10 \t loss 67.98675994575024\n","epoch 11 \t loss 65.67561437934637\n","epoch 12 \t loss 51.92248048633337\n","epoch 13 \t loss 46.50503298267722\n","epoch 14 \t loss 43.253642812371254\n","epoch 15 \t loss 65.30806917324662\n","epoch 16 \t loss 54.64137262851\n","epoch 17 \t loss 39.730345241725445\n","epoch 18 \t loss 36.79890500754118\n","epoch 19 \t loss 32.542437890544534\n","epoch 20 \t loss 40.21688421629369\n","epoch 21 \t loss 34.443190230987966\n","epoch 22 \t loss 28.707818317227066\n","epoch 23 \t loss 34.03942531673238\n","epoch 24 \t loss 30.04968861490488\n","epoch 25 \t loss 25.109764070250094\n","epoch 26 \t loss 22.695261615794152\n","epoch 27 \t loss 25.481391134671867\n","epoch 28 \t loss 24.98621327150613\n","epoch 29 \t loss 19.20919986255467\n","epoch 30 \t loss 24.53386156912893\n","epoch 31 \t loss 21.9943240522407\n","epoch 32 \t loss 18.519644377520308\n","epoch 33 \t loss 26.478650949895382\n","epoch 34 \t loss 19.247888281475753\n","epoch 35 \t loss 17.791392531013116\n","epoch 36 \t loss 19.346881803590804\n","epoch 37 \t loss 18.298393005039543\n","epoch 38 \t loss 14.560539441066794\n","epoch 39 \t loss 16.616738639539108\n","epoch 40 \t loss 16.301715011242777\n","epoch 41 \t loss 12.706050375010818\n","epoch 42 \t loss 11.520126551156864\n","epoch 43 \t loss 10.9290165042039\n","epoch 44 \t loss 14.60076261596987\n","epoch 45 \t loss 12.394543076399714\n","epoch 46 \t loss 9.321455943747424\n","epoch 47 \t loss 14.761011756607331\n","epoch 48 \t loss 13.582804599311203\n","epoch 49 \t loss 10.54582360200584\n","done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c0ZSqRE6omV9"},"source":["改良モデル推論・精度算出"]},{"cell_type":"code","metadata":{"id":"m2dWHkjWn9aJ","executionInfo":{"status":"ok","timestamp":1603122578684,"user_tz":-540,"elapsed":15361736,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"4ff01445-9efb-4b96-c69a-13eef98663fe","colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["model_deep_acc = accuracy(test_x_full, test_y_full, model_deep)\n","print(\"model_base accuracy :\", model_base_acc)\n","print(\"model_drop accuracy :\", model_drop_acc)\n","print(\"model_full accuracy :\", model_full_acc)\n","print(\"model_deep accuracy :\", model_deep_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["model_base accuracy : 0.6795392953929539\n","model_drop accuracy : 0.7730352303523035\n","model_full accuracy : 0.9092140921409214\n","model_deep accuracy : 0.9153116531165312\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q-qf57bvr1vD","executionInfo":{"status":"ok","timestamp":1603123232613,"user_tz":-540,"elapsed":114579,"user":{"displayName":"oimo","photoUrl":"","userId":"17558479998424245941"}},"outputId":"f0d73d27-06fc-4f9a-f987-29e4c148961a","colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["model_full_acc_train = accuracy(train_x_full, train_y_full, model_full)\n","print(\"model_full train accuracy :\", model_full_acc_train)\n","model_deep_acc_train = accuracy(train_x_full, train_y_full, model_deep)\n","print(\"model_deep train accuracy :\", model_deep_acc_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["model_full train accuracy : 0.9820338983050847\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["model_deep train accuracy : 0.995593220338983\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jLLqYZOMj1uz"},"source":["モデルの改良によりわずかに精度が向上したが、学習時間（約4時間）の割に大きな改善は見られなかった。\n","\n","改良モデルの学習データに対する精度を見ると、99%以上であり、過学習気味であることがわかる。これはモデルの複雑さが増したことに由来するものと考えられる。"]},{"cell_type":"markdown","metadata":{"id":"DPKSuyRZmWDx"},"source":["# 【まとめ】\n","\n","今回はLSTMを用いた文書分類にチャレンジした。\n","\n","その結果、ベースモデルでは過学習を引き起こしていることがわかった。そこでドロップアウトをモデルに適用したところ、過学習を抑制し、汎化性能を向上させることができた。\n","\n","また、今回はニュース記事の分類を行ったが、記事のタイトルのみならず、本文も入力データとすることで約90%の精度を出すことができた。\n","これは、本文中に特徴的な単語が多数含まれていること、LSTMが長い系列データに対しても学習可能であることが要因と考えられる。\n","\n","一方でLSTMモデルの多層化、Bidirectional化を試したが、大きな改善は見られなかった。細かいチューニングによって改善する可能性はあると思われる。\n","\n","\n","\n","\n","---\n","\n","参考文献\n","\n","[1]PyTorchを使ってLSTMで文章分類を実装してみた（バッチ化対応ver）https://qiita.com/m__k/items/db1a81bb06607d5b0ec5\n","\n","[2]PyTorchのBidirectional LSTMのoutputの仕様を確認してみた\n","https://qiita.com/m__k/items/78a5125d719951ca98d3"]}]}
